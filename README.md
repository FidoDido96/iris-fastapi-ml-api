# 🤖 Iris ML Prediction API with FastAPI & Docker 🐳

[![Python](https://img.shields.io/badge/Python-3.9%2B-blue?logo=python)](https://www.python.org/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.111.0-009688?logo=fastapi)](https://fastapi.tiangolo.com/)
[![Docker](https://img.shields.io/badge/Docker-26.1-blue?logo=docker)](https://www.docker.com/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT) 
## ✨ Project Overview

This project implements a machine learning prediction API for the classic Iris dataset using **FastAPI**. The core of the application is a pre-trained scikit-learn Gradient Boosting Classifier model. The entire application is **containerized with Docker** for easy deployment and portability, allowing anyone to run the API consistently across different environments.

The API provides an endpoint to receive new Iris flower measurements and return predictions (species), along with the associated probabilities and log probabilities.

## 🚀 Features

* **FastAPI Framework:** ⚡️ Modern, fast (high-performance), web framework for building APIs with Python 3.7+ based on standard Python type hints.
* **Machine Learning Model:** 🌳 Utilizes a pre-trained Gradient Boosting Classifier model to predict Iris species.
* **Docker Containerization:** 📦 Ensures consistent environments and simplified deployment.
* **Automated API Documentation:** 📖 Interactive API documentation (Swagger UI) automatically generated by FastAPI.
* **Robust Input Validation:** ✅ Pydantic models for data validation, ensuring clean and expected input.
* **Structured Project Layout:** 📁 Organized codebase for maintainability and scalability.

## 📂 Project Structure

iris_api/
├── app.py                     # Main FastAPI application
├── Dockerfile                 # Docker build instructions
├── requirements.txt           # Python dependencies
├── .gitignore                 # Files/folders to ignore in Git
├── models/
│   ├── ml/
│   │   └── iris_dt_v1.joblib  # Pre-trained ML model
│   └── schemas/
│       └── iris.py            # Pydantic schemas for request/response
│   └── classifier.py          # Model loading and prediction logic
├── routes/
│   └── v1/
│       └── iris_predict.py    # API endpoint for Iris prediction
└── train.py                   # Script to train and save the ML model



## 🛠️ Setup and Installation

### Prerequisites

Before you begin, ensure you have the following installed:

* **Docker Desktop:** [Download Docker](https://www.docker.com/products/docker-desktop/)
* **Git:** [Download Git](https://git-scm.com/downloads)
* **Python 3.9+:** [Download Python](https://www.python.org/downloads/) (Optional, if only running with Docker)
* **`pip`:** Python package installer (usually comes with Python)

### Local Setup (without Docker)

1.  **Clone the repository:**
    ```bash
    git clone [https://github.com/FidoDido96/iris-fastapi-ml-api.git](https://github.com/FidoDido96/iris-fastapi-ml-api.git)
    cd iris-fastapi-ml-api
    ```
2.  **Create a virtual environment (recommended):**
    ```bash
    python -m venv venv
    # On Windows
    .\venv\Scripts\activate
    # On macOS/Linux
    source venv/bin/activate
    ```
3.  **Install dependencies:**
    ```bash
    pip install -r requirements.txt
    ```
4.  **Train and save the model (if `models/ml/iris_dt_v1.joblib` doesn't exist):**
    ```bash
    python train.py
    ```
5.  **Run the FastAPI application:**
    ```bash
    uvicorn app:app --host 0.0.0.0 --port 8000 --reload
    ```
    The API will be accessible at `http://localhost:8000`.

### 🐳 Running with Docker (Recommended)

1.  **Clone the repository:**
    ```bash
    git clone [https://github.com/FidoDido96/iris-fastapi-ml-api.git](https://github.com/FidoDido96/iris-fastapi-ml-api.git)
    cd iris-fastapi-ml-api
    ```
2.  **Build the Docker image:**
    ```bash
    docker build -t iris-fastapi-app .
    ```
3.  **Run the Docker container:**
    ```bash
    docker run -p 8000:5000 --name iris-container iris-fastapi-app
    ```
    * `-p 8000:5000`: Maps host port `8000` to container port `5000` (where Uvicorn runs inside Docker).
    * `--name iris-container`: Assigns a readable name to your container.
    * The API will be accessible at `http://localhost:8000`.

    To stop the container:
    ```bash
    docker stop iris-container
    ```
    To remove the container:
    ```bash
    docker rm iris-container
    ```

## 🧪 API Usage

Once the API is running (either locally or via Docker), you can interact with it.

### Swagger UI (Interactive Documentation)

Open your web browser and navigate to:
[http://localhost:8000/docs](http://localhost:8000/docs)

Here you can see the API schema, try out the endpoint, and view example requests/responses.

### Using cURL (Command Line)

Send a POST request to the prediction endpoint:

```bash
curl -X 'POST' \
  http://localhost:8000/v1/iris/predict \
  -H 'accept: application/json' \
  -H 'Content-Type: application/json' \
  -d '{"data": [[4.8, 3.0, 4.0, 0.3], [2.1, 3.2, 1.1, 1.5]]}'
```
